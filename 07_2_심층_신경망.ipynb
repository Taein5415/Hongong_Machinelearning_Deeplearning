{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPeBe7yAksLaGP1ZP9pSGQU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#2개의 층\n",
        "케라스 API를 사용하여 패션 MNIST 데이터셋을 불러온다.\n"
      ],
      "metadata": {
        "id": "QUd17Pb2ak3h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvZxwbX6XgCG",
        "outputId": "2e9a068c-5269-4c7f-c41f-e208eaae8bd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음으로 이미지의 픽셀값을 0에서 255범위에서 0~1 사이로 변환하고, 28*28 크기의 2차원 배열을 784 크기의 1차원 배열로 펼친다. 그 후 훈련 세트와 검증 세트로 나눈다."
      ],
      "metadata": {
        "id": "oy5hM40WakZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_scaled = train_input/255.0\n",
        "train_scaled = train_scaled.reshape(-1,28*28)\n",
        "train_scaled, val_scaled, train_target, cal_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "MWRrBdN2bP0t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   은닉층 : 입력층과 출력층 사이에 있는 모든 층\n",
        "\n",
        "은닉층에는활성화 함수라는 것이 있다.\n",
        "\n",
        "\n",
        "\n",
        "*   활성화 함수 : 신경망 층의 선형 방정식의 계산 갑셍 적용하는 함수\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BYW-lYMobu95"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음으로 시그모이드 활성화 함수를 사용한 은닉층과 소프트맥스 함수를 사용한 출력층을 케라스의 Dense 클래스로 만든다."
      ],
      "metadata": {
        "id": "w2EY_E8QdcEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,))\n",
        "dense2 = keras.layers.Dense(10, activation='softmax')"
      ],
      "metadata": {
        "id": "ndmz-2w5dmUS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dense1은 은닉층이고 100개의 뉴런을 가진 밀집층이다. 활성화 함수는 sigmoid이고 input_shape 매개변수에서 입력의 크기를 (784,)로 지정했다.      \n",
        "이때 뉴런의 개수를 정하는 데에는 특별한 기준이 없다. 많은 경험을 통해 알아가야 한다."
      ],
      "metadata": {
        "id": "_NDH-Btqegwz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "한가지 제약사항이 있다. 은닉층의 뉴런은 적어도 출력층의 뉴런보다 많게 만들어야 한다."
      ],
      "metadata": {
        "id": "43rv36-De7-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "dense2는 출력층이다. 10개의 클래스를 분류하므로 10개의 뉴런을 두고, 활성화 함수는 소프트맥스 함수로 지정했다."
      ],
      "metadata": {
        "id": "ImnLIEA4fHpf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#인공 신경망 만들기\n",
        "이제 dense1, dense2 객체를 Sequential 클래스에 추가하여 심층 신경망을 만들어본다."
      ],
      "metadata": {
        "id": "Ulgdf1NwfR-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([dense1, dense2])"
      ],
      "metadata": {
        "id": "jTlzTZ3KgRqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "여러개의 층을 추가하기 위해 dense1, dense2를 리스트로 만들어 전달한다. 이때 출력층을 가장 마지막에 두어야 한다는 것이다."
      ],
      "metadata": {
        "id": "7vj176hnfitG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "케라스 모델의 summary 메서드를 호출해 층에 대한 정보를 확인할 수 있다."
      ],
      "metadata": {
        "id": "tM69i0LbgTsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfWuH3qDgaCl",
        "outputId": "5b868d77-b74a-44ab-a588-373464a775a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "처음 모델의 이름이 나온다. 그 다음 모델에 들어있는 층이 순서대로 나열된다. 이 순서는 맨 처음 추가한 은닉층에서 출력층의 순서대로 출력된다."
      ],
      "metadata": {
        "id": "HeqqhHH-gbkN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "맨 처음의 출력 크기는 (None, 100)이다. 첫번재 자원은 샘플의 개수를 뜻하고 두번째는 출력 개수이다."
      ],
      "metadata": {
        "id": "_5f6bkZ4g-ar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 미니 배치 경사 하강법을 사용하여 데이터를 모두 한번에 사용하지 않고 잘게 나누어 여러 번에 걸쳐 경사 하강법 단계를 수행하기 때문이다."
      ],
      "metadata": {
        "id": "EnfoNnvxiBPi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "따라서 샘플마다 784개의 픽셀 값이 은닉층을 통과하면서 100개의 특성으로 압축된 것이다."
      ],
      "metadata": {
        "id": "EcLVs8gciDwj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##층을 추가하는 다른 방법\n",
        "층을 추가하는 다은 방법으로는 Sequential 클래스의 생성자 안에서 바로 Dense 클래스의 객체를 만드는 것이다."
      ],
      "metadata": {
        "id": "rACiVLUiiOwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'),\n",
        "    keras.layers.Dense(10, activation='softmax', name='output')],\n",
        "                         name='패션 MNIST 모델')"
      ],
      "metadata": {
        "id": "m0TQGynciZKT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이렇게 작업하면 한 번에 층을 알아볼 수 있다는 장점이 있다. 이번에는 name 매개변수로 모델의 이름을 지정햇다. 또한 은닉층과 출력층 또한 이름을 붙여줬다."
      ],
      "metadata": {
        "id": "Um9ubARYis8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZMP_jasjFbq",
        "outputId": "07597c9c-bf5f-4df6-9690-7d4a86b5dafe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"패션 MNIST 모델\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden (Dense)              (None, 100)               78500     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "동일한 Dense 층과 파라미터 개수를 확인할 수 있다. 또한 name 매개변수로 이름을 지정해 층을 구분하기 쉬워졌다."
      ],
      "metadata": {
        "id": "Vtbvw48-jJy8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "또 다른 방법으로 add() 메서드를 사용하는 방법이 있다.  "
      ],
      "metadata": {
        "id": "As55nby0jWbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,)))\n",
        "model.add(keras.layers.Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "T0HY46WqjiD8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위와 같이 add메서드를 사용하면 한번에 추가되는 층을 볼수 있고, 동적으로 층을 선택하여 추가할 수도 있다."
      ],
      "metadata": {
        "id": "MLtAwEoYj0Vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBQdQWn_j9g-",
        "outputId": "d911be85-717c-4ad9-c4f0-d5a6a2d92d18"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "처음과 같은 결과를 얻을 수 있다."
      ],
      "metadata": {
        "id": "QV0CDGzHj_Y9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 모델을 훈련해본다 compile() 메서드를 사용하고 fit()의 매개변수 epochs로 5번 훈련한다."
      ],
      "metadata": {
        "id": "ZHODm-3BtAte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOgR0fg1j-z-",
        "outputId": "dd64c5c9-c439-4743-f01c-4bf7a4b6ccdb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5678 - accuracy: 0.8075\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4102 - accuracy: 0.8542\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3765 - accuracy: 0.8645\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3537 - accuracy: 0.8720\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3359 - accuracy: 0.8781\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7986d71eabc0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#렐루 함수\n",
        "초기 인공 신경망의 은닉층에 많이 사용된 활성화 함수는 시그모이드 함수였다. 하지만 이 함수에는 단점이 있다. 함수가 왼쪽 끝과 오른쪽 끝으로 누워있기 때문에 올바른 출력을 만드는데 신속하게 대응하지 못한다는 것이다."
      ],
      "metadata": {
        "id": "k0zsIZGMtzpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이를 개선하기 위해 렐루 함수가 제안되었다.\n",
        "\n",
        "\n",
        "*   렐루 함수 : 입력이 양수일 경우 마치 활성화 함수가 없는 것처럼 그냥 입력을 통과시키고 음수일 경우에는 0으로 만드는 함수이다.\n",
        "\n",
        "렐루 함수는 특히 이미지 처리에서 좋은 성능을 낸다고 알려져 있다.\n",
        "\n"
      ],
      "metadata": {
        "id": "V-ihASdUuHvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Flatten 클래스\n",
        "Flatten 클래스느느 배치 차원을 제외하고 나머지 읿력 차원을 모두 일렬로 펼치는 역할을 한다. 인공 신경망의 성능을 위해 기여하는 바는 없지만 입력층과 은닉층 사이에 추가하기 때문에 층이라 부른다."
      ],
      "metadata": {
        "id": "I_UyJCpxudOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
        "model.add(keras.layers.Dense(100,activation='relu'))\n",
        "model.add(keras.layers.Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "2Y_8eIXqut70"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "첫 번째 Dense 층에 있던 input_shape 매개변수를 Flatten 층으로 옮겼다. 또한 첫 번재 Dense 층의 활성화 함수를 relu로 바꿨다."
      ],
      "metadata": {
        "id": "ayK-eCb2vA9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDpFs6RPvm_d",
        "outputId": "50ed7d66-7779-451e-fa93-b53d0e39f29b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "flatten 층의 파라미터는 0개이다. 케라스의 Flatten 층을 신경망 모델에 추가하면 입력 값의 차원을 짐작할 수 있는 것이 장점이다. 위의 출력을 보면 (NOne, 784)를 통해 784개의 입력을 알 수 있다."
      ],
      "metadata": {
        "id": "c-L6c-Hwvt9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다시 훈련 데이터를 준비해서 모델을 훈련해본다. 이 때 앞선 전처리와 다르게 reshape 메서드를 이용해 배열의 크기를 바꾸지 않는다."
      ],
      "metadata": {
        "id": "TUbOUdfkwMgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
        "train_scaled = train_input/255.0\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "5zzEgl1VwZa9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOVWFs3Iwjp8",
        "outputId": "024aa701-8713-4a80-8956-1a8423803f79"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5324 - accuracy: 0.8122\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3937 - accuracy: 0.8587\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3571 - accuracy: 0.8720\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3342 - accuracy: 0.8791\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3194 - accuracy: 0.8837\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7986d452d000>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "시그모이드 함수보다 성능이 조금 향상됨을 볼 수 있다. 검증 세트에서의 성능 또한 확인해본다."
      ],
      "metadata": {
        "id": "C5htusIvwify"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(val_scaled, val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njk0d_N1wvv4",
        "outputId": "cda2e865-4bf5-4cea-ee33-ab366f402983"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3439 - accuracy: 0.8821\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.34393155574798584, 0.8820833563804626]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#옵티마이저\n",
        "\n",
        "3장에서 하이퍼 파라미터는 모델이 학습하지 않아 사람이 지정해주어야 하는 파라미터라고 했다. 신경망에는 하이퍼 파라미터가 많다.\n",
        "\n"
      ],
      "metadata": {
        "id": "cZhb-IhcxIWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "추가할 은닉층의 개수 또한 우리가 지정해야 하는 하이퍼파아미터이다. 은닉층의 뉴런 개수 또한 하이퍼 파라미터이다."
      ],
      "metadata": {
        "id": "hxOq4ZBqxZTd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "케라스는 기본적으로 미니배치 경사 하강법을 사용하고, 미니배치의 개수는 기본적으로 32개지만 이 수치 또한 fit() 메서드의 fatch_size를 이용해 변경할 수 있고, 이 값 또한 하이퍼파라미터이다. epochs 또한 그렇다."
      ],
      "metadata": {
        "id": "PZoZQUB2xj_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "compile() 메서드에서는 케라스의 기본 경사 하강법 알고리즘인 RMSprop를 사용했다. 케라스는 다양한 종류의 경사 하강법 알고리즘을 제공하는데 이것들을 ***옵티마이저***라고 한다."
      ],
      "metadata": {
        "id": "4fW04nLwxz-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "가장 기본적인 옵티마이저는 확률적 경사 하강법인 SGD이다. 이름은 SGD이지만 기본적으로 미니 배치를 사용한다."
      ],
      "metadata": {
        "id": "Bh_hBmEqyTf3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGD 옵티마이저를 사용하려면 compile 메서드의 optimizer 매개변수 를 'sgd'라고 지정한다."
      ],
      "metadata": {
        "id": "oRCMvvAbydsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "x6HErY4vylAg"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 옵티마이저는 tensorflow.keras.optimizers 패키지 아래의 SGD 클래스로 구현되어 있다.      \n",
        "다음의 코드는 위의 코드와 일치하는 코드이다."
      ],
      "metadata": {
        "id": "Z2QK1NmlyzKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = keras.optimizers.SGD()\n",
        "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "CvaNd4j8y9I-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGD 클래스의 학습률 기본값은 0.01 이다. 이 때 이름을 바꾸고 싶다면 learning_rate 매개변수를 지정하여 사용한다."
      ],
      "metadata": {
        "id": "V_9Nek3nzZHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = keras.optimizers.SGD(learning_rate=0.1)"
      ],
      "metadata": {
        "id": "PrcGhZExyrPx"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 외에도 많은 옵티마이저들이 있다."
      ],
      "metadata": {
        "id": "4oIw1SCL0ULX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본 경사 하강법 옵티마이저는 모두 SGD클래스에서 제공한다. SGD 클래스의 momentum 매개변수의 기본값은 0이다. 이를 0보다 큰 값으로 지정하면 ***모멘텀 최적화***를 사용한다.\n",
        "\n",
        "\n",
        "*   모멘텀 가속화 : 이전의 그레이디언트를 가속도처럼 사용하는 방식\n",
        "\n",
        "보통 momentum 매개변수는 0.9 이상을 지정한다.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0ht9DyjJ0Y4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGD 클래스의 nesterov 매개변수를 기본값 False 에서 True로 바꾸면 ***네스테로프 모멘텀 최적화***를 사용한다."
      ],
      "metadata": {
        "id": "A5tgE_zK01dS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = keras.optimizers.SGD(momentum=0.9, nesterov=True)"
      ],
      "metadata": {
        "id": "SjET8Ga-1ECW"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "네스테로프 모멘텀은 모멘텀 최적화를 2번 반복하여 구현한다. 대부분은 네스테로프 모멘텀 최적화가 기본 확률적 경사 하강법보다 더 나은 성능을 제공한다."
      ],
      "metadata": {
        "id": "a85OEW_p1W_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   ***적응적 학습률*** : 모델이 최적점에 가까이 갈수록 학습률을 낮추는 것\n",
        "\n",
        "이러한 방식들을 통해 학습률 매개변수를 튜닝하는 수고를 덜 수 있다.\n",
        "\n"
      ],
      "metadata": {
        "id": "AFGYy3IS1nZ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "적응적 학습률을 사용하는 대표적인 옵티마이저는 RMSprop이다.    \n",
        "complie() 메서드의 optimizer 매개변수에 'adagrad'와 'rmsprop'로 지정할 수 있다.     \n",
        "optimizer 매개변수의 기본값은 rmsprop이다."
      ],
      "metadata": {
        "id": "R5BNe2mQ13A1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adagrad = keras.optimizers.Adagrad()\n",
        "model.compile(optimizer=adagrad, loss='sparse_categorival_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "z8XxGqaO2SGZ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSprop의 방식은 다음과 같다."
      ],
      "metadata": {
        "id": "2Lpi9ToB2iTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop = keras.optimizers.RMSprop()\n",
        "model.compile(optimizer=rmsprop, loss='sparse_categorival_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "MTbnRVIs2fFd"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모멘텀 최적화와 RMSprop의 장점을 접목한 것이 Adam이다. 이 3개의 클래스는 learning_rate 매개변수이 기본값으로 모두 0.001을 사용한다."
      ],
      "metadata": {
        "id": "hQ0MBY7e20E4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래에서는 Adam 클래스의 매개변수 기본값을 사용해여 패선 MNIST를 훈현한다.     \n",
        "모델 생성부터 다시 한다."
      ],
      "metadata": {
        "id": "HPtNZbPa3daD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
        "model.add(keras.layers.Dense(100,activation='relu'))\n",
        "model.add(keras.layers.Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "CjaiGDSX3kaC"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hnXbpqG3350",
        "outputId": "0f7d5732-1fee-43cc-eadc-cce030f4cf8f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5188 - accuracy: 0.8177\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3924 - accuracy: 0.8590\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3513 - accuracy: 0.8738\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3252 - accuracy: 0.8827\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3052 - accuracy: 0.8888\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7986cf79c520>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSprop를 사용했을 때와 거의 같은 성능을 보여둔다. 아래는 검증 세트에서의 성능이다."
      ],
      "metadata": {
        "id": "L0Z2iZrm4dS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(val_scaled, val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILtccafk4k9W",
        "outputId": "0610f9ac-5cba-44b1-9154-96e67ffbc898"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3741 - accuracy: 0.8672\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3741055428981781, 0.8671666383743286]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}